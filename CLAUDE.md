# HomeLab Project Documentation

## Overview

This project documents the research, planning, and setup of an affordable but powerful home laboratory environment designed to run local LLMs with medium context sizes.

**ðŸ“š Detailed Documentation**: See the `docs/` directory:
- **[llm-homelab-research-2025.md](docs/llm-homelab-research-2025.md)** - Comprehensive hardware research
- **[build-plan.md](docs/build-plan.md)** - Build plan with costs and implementation steps
- **[linux-os-comparison.md](docs/linux-os-comparison.md)** - Linux OS options for server (Proxmox, Ubuntu, etc.)
- **[changelog.md](docs/changelog.md)** - Version history

## Project Goals

1. **Server Component**: Reliable server infrastructure for hosting services
2. **LLM Workstation**: Computer/Mac capable of running local LLMs with medium context sizes
3. **Budget-Friendly**: Maximize performance within reasonable cost constraints
4. **Well-Integrated**: Components that work well together

## Current Status

**Phase**: Research Complete - Ready for Hardware Purchasing

**Recommended Build**: Budget-Conscious Starter ($2,200 total)
- LLM Workstation with used RTX 3090 24GB ($1,350)
- Beelink SER7 mini PC server ($700)
- 2.5GbE networking ($150)

See [docs/build-plan.md](docs/build-plan.md) for complete specifications and purchasing guide.

## Quick Reference

### Research Areas
- Server hardware options
- GPU requirements for local LLM inference
- RAM and storage requirements
- Networking equipment
- Cost optimization strategies

## Version History

**Full changelog**: [docs/changelog.md](docs/changelog.md)

### 2025-11-07 - Project Initialized
- Created project structure
- Defined project goals and scope
- Initiated research phase
